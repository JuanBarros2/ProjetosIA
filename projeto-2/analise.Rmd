---
title: "R Notebook"
output:
  html_document: default
  html_notebook: default
---

# Predição de preços de automóveis com Regressão Linear, ID3, KNN e XGB

Inicialmente realizaremos uma amostragem dos dados tendo em vista que a base de dados é muito grande e acaba necessitando de muita
memória para carrega-los todos em memória. Em seguida, é feito um particionamento de 80 por cento dos dados destinados ao treino
dos modelos e 20 por cento para validação, posteriormente. Além disso, é preciso ressaltar que foi feita uma análise prévia de importância das variáveis com uma amostragem e foi detectado que algumas variáveis tiveram importância muito pequena para o modelo. Por isso, resolvemos eliminar e aumentar o número de amostras que os modelos irão utilizar para melhor aprender.

```{r importandoDados}
library(tidyverse)
library(caret)

dadosBrutos <- read.csv("true_car_listings.csv")
particao <- createDataPartition(dadosBrutos$Price, p = .99, 
                                     list = FALSE, 
                                     times = 1)

dadosDisponiveis <- dadosBrutos[-particao,] %>% 
  select(-Vin, -Make, -City, -State)

particaoTT <- createDataPartition(dadosDisponiveis$Price, p = .8, 
                                     list = FALSE, 
                                     times = 1)
dadosTreino <- dadosDisponiveis[particaoTT,]
dadosValidacao <- dadosDisponiveis[-particaoTT,]
```

### Treinando os modelos

Para treinar os modelos descritos, realizaremos uma validação cruzada com 5-folds e repeti-la 10 vezes. Como queremos prever o preço,
utilizaremos "Price" como variável alvo para nossos modelos aprenderem. Além disso, utilizaremos o pre-processamento do caret que deixa
os valores em uma mesma escala.

```{r warnings=FALSE}
config <- trainControl(method = "repeatedcv", number = 5, repeats = 10)

linearRegressionModel <- train(Price ~ Mileage, 
                          data = dadosTreino , 
                          method = "lm", 
                          preProcess = c("center","scale"),
                          trControl = config)

k <- expand.grid(k = seq(20, 100, length=20))
knnModel <- train(Price ~ Mileage,
                     data = dadosTreino,
                     method = "knn",
                     preProcess = c("center","scale"),
                     tuneGrid = k,
                     trControl = config)

xgbModel <- train(Price ~ Mileage,
                     data = dadosTreino,
                     method = "xgbLinear",
                     preProcess = c("center","scale"),
                     trControl = config)

id3Model <- train(Price ~ Mileage,
                     data = dadosTreino,
                     method = "rpart",
                     preProcess = c("center","scale"),
                     trControl = config)
```

### Análise dos Modelos

#### Todos
```{r}
summary(resamples(list(LM = linearRegressionModel, ID3= id3Model, XGB = xgbModel, KNN = knnModel)))
```

#### Regressão Linear

```{r}
linearRegressionModel

```
```

#### KNN
```{r analiseKnn}
plot(knnModel)
```

#### ID3
```{r analiseid3}
plot(id3Model)
```

#### XGB
```{r analiseXgb}
plot(xgbModel)
```


### Análise das predições

Para realizar a análise das predições, utilizaremos os dados de validação que foram separados inicialmente, aplicando os modelos aos valores e comparando o valor de saída para avaliação dos modelos.

```{r}
knnPredic <- predict(knnModel, dadosValidacao)
regLinearPredic <- predict(linearRegressionModel, dadosValidacao)
id3Predic <- predict(id3Model, dadosValidacao)
xgbPredic <- predict(xgbModel, dadosValidacao)
```

```{r}
postResample(pred = knnPredic, obs = dadosValidacao$Price)
```

```{r}
postResample(pred = regLinearPredic, obs = dadosValidacao$Price)
```

```{r}
postResample(pred = id3Predic, obs = dadosValidacao$Price)
```

```{r}
postResample(pred = xgbPredic, obs = dadosValidacao$Price)
```
